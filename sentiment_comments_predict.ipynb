{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文情感预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8  -*-\n",
    "import sys\n",
    "import jieba # 用于中文分词\n",
    "import pandas\n",
    "\n",
    "# 默认提供的数据集data.csv在macOS下直接预读乱码，转存utf-8一份\n",
    "SORUCE_FILE = \"clean_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 从源数据中主要提取comment列和sentiment列\n",
    "source_file_df =  pandas.read_csv(SORUCE_FILE, header=None, names=['a', 'b', 'comment', 'frequence', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   a             b comment  frequence  sentiment\n0  1  1.055840e+10    东西好吃         41          1\n1  2  1.055840e+10    味道可以         37          1\n2  3  1.055840e+10       贵         35          0\n3  4  1.055840e+10    超快送达         35          1\n4  5  1.055840e+10   松子太好吃         32          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>comment</th>\n      <th>frequence</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.055840e+10</td>\n      <td>东西好吃</td>\n      <td>41</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.055840e+10</td>\n      <td>味道可以</td>\n      <td>37</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.055840e+10</td>\n      <td>贵</td>\n      <td>35</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.055840e+10</td>\n      <td>超快送达</td>\n      <td>35</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1.055840e+10</td>\n      <td>松子太好吃</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "source_file_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((8854, 1), (8854,))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "# 以comment列内容为属性\n",
    "X = source_file_df[['comment']]\n",
    "# 以sentiment列内容为lable，分类只有两类0消极或1积极\n",
    "y = source_file_df.sentiment\n",
    "X.shape, y.shape\n",
    "# print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/h3/xhgwsrzx56vclhvlkydknskw0000gn/T/jieba.cache\n",
      "Loading model cost 0.896 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/anaconda3/envs/py3pku/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "  comment cutted_comment\n0    东西好吃          东西 好吃\n1    味道可以          味道 可以\n2       贵              贵\n3    超快送达          超快 送达\n4   松子太好吃        松子 太 好吃",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>cutted_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>东西好吃</td>\n      <td>东西 好吃</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>味道可以</td>\n      <td>味道 可以</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>贵</td>\n      <td>贵</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>超快送达</td>\n      <td>超快 送达</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>松子太好吃</td>\n      <td>松子 太 好吃</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "# 调包侠关键步骤：使用jieba抽取comment列的内容进行分词，分词结果放到cutted_comment列中\n",
    "X['cutted_comment'] = X.comment.apply(lambda x: \" \".join(jieba.cut(x)))\n",
    "# 可以看出comment列分词后放到了cutted_comment\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 使用train_test_split将数据集切分，按照作业要求取6000条数据用于训练\n",
    "# 肉眼看train_test_split默认给打乱数据集了？？？？\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((6000, 2), (2854, 2), (6000,), (2854,))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "# 6000个训练属性，对应6000个标签\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 文本向量化处理，sklearntt提供两个方法：CountVectorizer TfidfVectorizer \n",
    "# 选择CountVectorizer，原因：1. 数据集似乎是精心准备，不用做复杂的停用词处理 2. 搜到的多数教程以CountVectorizer为例，选此少踩坑\n",
    "# 主要参考博客 https://www.cnblogs.com/Lin-Yi/p/8974108.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_count_train = count_vec.fit_transform(X_train.cutted_comment)\n",
    "x_count_test = count_vec.transform(X_test.cutted_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 使用朴素贝叶斯分类器  分别对两种提取出来的特征值进行学习和预测\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_count = MultinomialNB()\n",
    "mnb_count.fit(x_count_train, y_train)   # 学习\n",
    "mnb_count_y_predict = mnb_count.predict(x_count_test) #预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9663629992992292"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "mnb_count.score(x_count_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9632095304835319"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bn_count = BernoulliNB()\n",
    "bn_count.fit(x_count_train, y_train)\n",
    "bn_count_y_predict = bn_count.predict(x_count_test)\n",
    "bn_count.score(x_count_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9081990189208129"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "# sklearn.naive_bayes.ComplementNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "cnb_count = ComplementNB()\n",
    "cnb_count.fit(x_count_train, y_train)\n",
    "cnb_count_y_predict = cnb_count.predict(x_count_test)\n",
    "cnb_count.score(x_count_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "\n"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}